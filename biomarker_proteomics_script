# -----------------------------
# Config
# -----------------------------
np.random.seed(42)
n_splits = 50
train_ratio = 0.7
selected_genes = ["THBS1", "SOD3", "NID1"]

# -----------------------------
# Filter missing proteins using original data
# -----------------------------
protein_missing_rate = original_df.isna().mean(axis=1)
excluded_proteins = protein_missing_rate[protein_missing_rate > 0.1]
filtered_df = imputed_df.loc[~imputed_df.index.isin(excluded_proteins.index)]
print(f" Excluded {len(excluded_proteins)} proteins with >10% missing values")

# -----------------------------
# Transpose + extract labels
# -----------------------------
X = filtered_df.T
X.index.name = "sample"
X["condition"] = X.index.to_series().str.extract(
    r"(CTEPH_Large|CTEPH_Segmental|CTEPH_Organized|CTEPH_Fresh|Control_Large)", expand=False
)
X = X.dropna(subset=["condition"])
features = X.drop(columns="condition")
labels = X["condition"]

# -----------------------------
# Differential expression loop
# -----------------------------
comparisons = ["CTEPH_Large", "CTEPH_Segmental", "CTEPH_Organized", "CTEPH_Fresh"]
significance_results = {group: [] for group in comparisons}
fold_changes = {gene: [] for gene in features.columns}

for i in range(n_splits):
    train_indices = []
    for group in labels.unique():
        group_indices = labels[labels == group].index
        train_group, _ = train_test_split(
            group_indices, train_size=train_ratio, shuffle=True, random_state=42 + i
        )
        train_indices.extend(train_group)

    X_train = features.loc[train_indices]
    y_train = labels.loc[train_indices].reset_index(drop=True)

    for group in comparisons:
        ctrl_mask = y_train == "Control_Large"
        group_mask = y_train == group
        if ctrl_mask.sum() == 0 or group_mask.sum() == 0:
            continue

        ctrl_vals = X_train[ctrl_mask.values]
        group_vals = X_train[group_mask.values]

        _, p_vals = ttest_ind(group_vals, ctrl_vals, equal_var=False, nan_policy='omit')
        p_adj = multipletests(p_vals, method='fdr_bh')[1]
        sig_mask = p_adj < 0.05
        sig_genes = features.columns[sig_mask].tolist()
        significance_results[group].append(set(sig_genes))

        group_means = group_vals.mean(axis=0)
        ctrl_means = ctrl_vals.mean(axis=0)
        with np.errstate(divide='ignore', invalid='ignore'):
            log2fc = np.log2(group_means / ctrl_means).replace([np.inf, -np.inf], np.nan)

        for gene in sig_genes:
            if pd.notna(log2fc[gene]):
                fold_changes[gene].append(log2fc[gene])

# -----------------------------
# Consistent biomarkers
# -----------------------------
consistent_genes = {
    group: set.intersection(*runs) if runs else set()
    for group, runs in significance_results.items()
}
shared_biomarkers = set.intersection(*[
    consistent_genes[g] for g in comparisons if consistent_genes[g]
])

# -----------------------------
# Filter for ↑ or ↓ (exclude mixed)
# -----------------------------
directionality = {}
for gene, fc_list in fold_changes.items():
    if gene not in shared_biomarkers:
        continue
    if all(fc > 0 for fc in fc_list):
        directionality[gene] = "↑ Increased"
    elif all(fc < 0 for fc in fc_list):
        directionality[gene] = "↓ Decreased"
    else:
        directionality[gene] = "↕ Mixed"

filtered_biomarkers = [
    g for g in shared_biomarkers if directionality.get(g) in ("↑ Increased", "↓ Decreased")
]

# -----------------------------
# Summary output
# -----------------------------
summary_df = pd.DataFrame({
    "Gene": filtered_biomarkers,
    "Avg |log2FC|": [np.mean(np.abs(fold_changes[g])) for g in filtered_biomarkers],
    "Num Comparisons": [len(fold_changes[g]) for g in filtered_biomarkers],
    "Direction": [directionality[g] for g in filtered_biomarkers]
}).sort_values(by="Avg |log2FC|", ascending=False).reset_index(drop=True)

print(f"\n Final consistently significant biomarkers (excluding mixed): {len(filtered_biomarkers)}")
print("\n Summary of Differentially Expressed Genes:")
print(summary_df.to_string(index=False))

# -----------------------------
# Secretome match
# -----------------------------
secreted_matches = secretome_df[secretome_df["Gene name"].isin(filtered_biomarkers)]
secreted_genes = secreted_matches["Gene name"].tolist()

print("\n Matched to secretome:")
print(secreted_matches[["Gene name", "Annotated category"]])

unmatched = [g for g in filtered_biomarkers if g not in secreted_genes]
print("\n Not matched:")
print(unmatched)

# -----------------------------
# Logistic regression bootstrap on THBS1 + SOD3 + NID1 (combined panel)
# -----------------------------
def evaluate_markers_bootstrap_with_roc_ppv_npv(control_df, case_df, markers, name, n_iterations=100, seed=42):
    rng = np.random.default_rng(seed)
    results = []
    coefs = []

    # Use the combination of markers as a feature set
    control_data = control_df[markers]
    case_data = case_df[markers]

    X_all = pd.concat([control_data, case_data])
    y_all = np.concatenate([np.zeros(control_data.shape[0]), np.ones(case_data.shape[0])])
    n_samples = len(X_all)

    for _ in range(n_iterations):
        boot_idx = rng.choice(n_samples, size=n_samples, replace=True)
        oob_mask = np.ones(n_samples, dtype=bool)
        oob_mask[boot_idx] = False

        X_boot, y_boot = X_all.iloc[boot_idx], y_all[boot_idx]
        X_oob, y_oob = X_all.iloc[oob_mask], y_all[oob_mask]

        if len(np.unique(y_oob)) < 2:
            continue

        model = LogisticRegressionCV(cv=3, max_iter=1000, scoring='roc_auc', class_weight='balanced')
        model.fit(X_boot, y_boot)

        y_pred = model.predict(X_oob)
        y_prob = model.predict_proba(X_oob)[:, 1]

        try:
            tn, fp, fn, tp = confusion_matrix(y_oob, y_pred).ravel()
            sensitivity = tp / (tp + fn) if (tp + fn) else np.nan
            specificity = tn / (tn + fp) if (tn + fp) else np.nan
            ppv = tp / (tp + fp) if (tp + fp) else np.nan
            npv = tn / (tn + fn) if (tn + fn) else np.nan
        except ValueError:
            sensitivity = specificity = ppv = npv = np.nan

        auc_score = roc_auc_score(y_oob, y_prob)

        results.append({
            "AUC": auc_score,
            "Sensitivity": sensitivity,
            "Specificity": specificity,
            "PPV": ppv,
            "NPV": npv
        })
        coefs.append(model.coef_[0])

    metrics_df = pd.DataFrame(results)
    coefs_df = pd.DataFrame(coefs, columns=markers)
    summary = pd.concat([
        metrics_df.describe().loc[["mean", "std"]],
        coefs_df.describe().loc[["mean", "std"]].add_prefix("Coef_")
    ], axis=1)

    return summary

# Prepare datasets for CTEPH vs Control
datasets = {}
for group in ["CTEPH_Large", "CTEPH_Segmental", "CTEPH_Organized", "CTEPH_Fresh"]:
    group_samples = labels[labels == group].index
    datasets[group] = features.loc[group_samples, selected_genes]

Control = features.loc[labels[labels == "Control_Large"].index, selected_genes]

# Run bootstrap validation for each group
bootstrap_results = {}
for name, case_df in datasets.items():
    print(f"\nRunning bootstrap + ROC + PPV/NPV for {name}...")
    df = evaluate_markers_bootstrap_with_roc_ppv_npv(Control, case_df, selected_genes, name, n_iterations=100)
    bootstrap_results[name] = df

# Combine results and save
summary_table = pd.concat(bootstrap_results, axis=1)
print(summary_table)

summary_table.to_excel("bootstrap_summary.xlsx")
print("\n Saved bootstrap validation summary to: bootstrap_summary.xlsx")
